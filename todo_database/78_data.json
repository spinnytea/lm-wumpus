{"name":"Multiple Sensors; Different perspectives","description":"We need different ways or representing the data, different perspectives on the same situation.\n\nMotivation\nWhen checking to see what room the agent is in, we basically need to do collision detection on each room. Which means we need to list out all the rooms. This simple method has an input size of agent+all rooms.\nWell is there a way to cull that information first?\nI do it by looking at the map where the agent is, and only considering the nearby rooms. I don't need to see ALL of them, just the ones that fit on screen. That's because I'm using different sensors than the computer.\nThe computer only has \"a map of all the ideas,\" I only have \"a rasterized image.\"","resolution":""}