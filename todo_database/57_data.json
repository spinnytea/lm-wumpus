{"name":"Kinds of sensor processors","description":"What does it mean to identify a room based on location/properties? We can create a subgraph match to identify it, but how do we link it together? Is it one sensor that produces a match for any room, or do we need a new sensor for each room?\nIt's easy to identify that something is a type of room, but how do we identify a specific room?\n\nAre there other kinds of sensors? Some based on calculation?\n\nHow does all this play into learning about sensors? (with respect to what matters and what doesn't)\nFor example\nit matters that a room CAN HAVE a pit/gold/exit, but it doesn't matter what the values are.\nit matters what the location of the room is, and the values of the x and y\n\nHere's a starting point:\nFirst: think about what it would take to identify a room. If I implemented a way to say \"this is a room, this is a room, this is not a room, this is also a room\"; What would it look like, what would it produce? How does that compare to \"this is room 1, this is room 2, etc\".\nThen: think about what it would take to say \"the player is in the room, the player is not in the room\"\n\nMy first thought: math sensor, distance from the center. Again, is it generic or specific?\nWe can sweat the details of how we create a sensor based on distance later, for now, we just need to worry about having one.","resolution":"TL;DR: Do whatever you need to get the first sensor working.\nSensors will key off a subgraph search, and make modifications (similar to transitions, but will create new nodes if needed).\n\nThe functional portion of it can be hard coded for now.\n\nThe epiphany came with people and visuals. People learn to use their vision as they grow. They learn that a \"dot\" can be \"inside\" another \"circle.\" This is what it means for an agent to be in a room, this is why I draw something visual to the screen, so I - the person - can see it. But the LM cannot process this information. The LM hasn't spent the time building up visual models of what it means to be inside of something.\n\nThe way I want to represent \"inside\" for the LM is based on distance, or math. But I haven't taught it any math. I haven't taught it to make connections between different kinds of models, and I haven't taught it how to optimize it's math by using a library.\nSo.\nMy first sensor will be hard coding that optimized sensor the way I expect it will be eventually produced."}